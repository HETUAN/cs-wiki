(window.webpackJsonp=window.webpackJsonp||[]).push([[120],{588:function(v,_,t){"use strict";t.r(_);var e=t(29),l=Object(e.a)({},(function(){var v=this,_=v.$createElement,t=v._self._c||_;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("h1",{attrs:{id:"阿里实习一面-内存放不下-如何在-20-亿个整数中找到出现次数最多的数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#阿里实习一面-内存放不下-如何在-20-亿个整数中找到出现次数最多的数"}},[v._v("#")]),v._v(" 阿里实习一面，内存放不下，如何在 20 亿个整数中找到出现次数最多的数")]),v._v(" "),t("hr"),v._v(" "),t("p",[v._v("题目是这样的：")]),v._v(" "),t("ul",[t("li",[v._v("有一个大文件，文件里面都是数字，无法全部加载到内存中，如何查找出现次数最多的数字？")])]),v._v(" "),t("p",[v._v("对于这种大数据小内存问题，其实解法都大差不差，常见的就是两种：")]),v._v(" "),t("ol",[t("li",[v._v("分治法")]),v._v(" "),t("li",[v._v("位图法")])]),v._v(" "),t("p",[v._v("前面两篇文章也介绍了一点，可以回顾一下~")]),v._v(" "),t("br"),v._v(" "),t("p",[v._v("对于查找出现次数最多（or 最少）的数字问题，通常的做法是用哈希表对出现的每一个数做频率统计，key 存储整数值，value 存储这个数出现的次数，然后遍历一遍哈希表找到出现次数最多（最少）的那个数值就行了。")]),v._v(" "),t("p",[v._v("但是如果数字数量很多的话，比如 20 亿，哈希表需要开辟多大的空间？")]),v._v(" "),t("p",[v._v("假设所有的数字都是 int 类型，占 4 个字节，也就是哈希表的 key 需要 4 个字节，然后 value 也用 int 表示，这样，哈希表的一个 entrySet（一条 key-value 记录） 就需要占 8 个字节（8B）")]),v._v(" "),t("p",[v._v("考虑正常情况，20 亿个数大概只有 2 亿个不同的数，那么哈希表就需要 2 亿个 entrySet 才能处理，也就是 16 亿个字节，差不多就是 1.6 GB")]),v._v(" "),t("p",[v._v("考虑极端情况，20 亿个数全都不相同，那就是什么情况，哈希表需要 20 亿个 entrySet 才能处理，也就是 160 亿个字节，差不多就是 16 GB")]),v._v(" "),t("p",[v._v("显然，用哈希表一次性去处理 20 亿个数的内存风险是很大的。")]),v._v(" "),t("p",[v._v("解决办法是：")]),v._v(" "),t("ol",[t("li",[v._v("把包含 20 亿个数的大文件用哈希函数分成若干个小文件，根据哈希函数的性质，同一种数不可能被散列到不同的小文件上")]),v._v(" "),t("li",[v._v("然后对每一个小文件用哈希表来统计其中每种数出现的次数，这样我们就得到了若干个小文件中各自出现次数最多（最少）的数")]),v._v(" "),t("li",[v._v("最后比较这若干个小文件各自的第一名中谁出现的次数最多（最少）即可")])]),v._v(" "),t("p",[v._v("总结下，其实就是"),t("strong",[v._v("分治法 + 哈希表")])])])}),[],!1,null,null,null);_.default=l.exports}}]);